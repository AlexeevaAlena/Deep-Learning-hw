{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cea94795-d663-499f-ad18-a458da6e036f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T14:41:33.259535Z",
     "iopub.status.busy": "2025-05-17T14:41:33.258628Z",
     "iopub.status.idle": "2025-05-17T14:41:35.620830Z",
     "shell.execute_reply": "2025-05-17T14:41:35.619796Z",
     "shell.execute_reply.started": "2025-05-17T14:41:33.259500Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.6)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "dd49c55d-409c-4c0e-85d9-6b4909d5ff2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T20:19:05.892498Z",
     "iopub.status.busy": "2025-05-17T20:19:05.891393Z",
     "iopub.status.idle": "2025-05-17T20:19:06.059768Z",
     "shell.execute_reply": "2025-05-17T20:19:06.058956Z",
     "shell.execute_reply.started": "2025-05-17T20:19:05.892455Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from transformers import LlamaTokenizer, LlamaForSequenceClassification, TrainingArguments, AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding, LlamaTokenizerFast\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import pipeline\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import zipfile\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from torch.cuda.amp import autocast\n",
    "from ctransformers import AutoModelForCausalLM\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bc90be1-b8de-43fa-86b7-36c1d1b62611",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T14:39:06.015643Z",
     "iopub.status.busy": "2025-05-17T14:39:06.014693Z",
     "iopub.status.idle": "2025-05-17T14:39:08.872834Z",
     "shell.execute_reply": "2025-05-17T14:39:08.872006Z",
     "shell.execute_reply.started": "2025-05-17T14:39:06.015593Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/jupyter/work/resources/kaggle.json'\n",
      "Downloading dl-2025-study-competition-2.zip to /home/jupyter/work/resources\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12.9M/12.9M [00:01<00:00, 10.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c dl-2025-study-competition-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c0a34d5-38d9-48bf-be0f-d4e28ca5e97c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T14:39:53.946017Z",
     "iopub.status.busy": "2025-05-17T14:39:53.945164Z",
     "iopub.status.idle": "2025-05-17T14:39:56.571309Z",
     "shell.execute_reply": "2025-05-17T14:39:56.570592Z",
     "shell.execute_reply.started": "2025-05-17T14:39:53.945992Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "with zipfile.ZipFile('dl-2025-study-competition-2.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('data')\n",
    "\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "submission_df = pd.read_csv('data/sample_submission.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b69a3e8b-806b-47a4-ba37-65214ac79072",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T14:39:59.007559Z",
     "iopub.status.busy": "2025-05-17T14:39:59.006479Z",
     "iopub.status.idle": "2025-05-17T14:39:59.102368Z",
     "shell.execute_reply": "2025-05-17T14:39:59.101520Z",
     "shell.execute_reply.started": "2025-05-17T14:39:59.007526Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29568, 3) (7392, 2)\n",
      "   id  ...                                   labels\n",
      "0   0  ...  1 0 0 0 1 0 0 0 1 0 0 0 1 1 1 1 1 0 0 1\n",
      "1   1  ...  0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 1\n",
      "2   2  ...  0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1\n",
      "3   3  ...  1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0\n",
      "4   4  ...  1 1 0 0 0 0 0 1 1 0 0 1 1 1 1 0 1 1 1 0\n",
      "\n",
      "[5 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape,\n",
    "      test_df.shape)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07043571-4f9b-41ff-9bd1-7cab292f65e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T14:40:02.481483Z",
     "iopub.status.busy": "2025-05-17T14:40:02.480360Z",
     "iopub.status.idle": "2025-05-17T14:40:02.638322Z",
     "shell.execute_reply": "2025-05-17T14:40:02.637481Z",
     "shell.execute_reply.started": "2025-05-17T14:40:02.481439Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         int64\n",
       "text      object\n",
       "labels    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fc02796-6e1b-4b4f-8e3f-a285dcebc669",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T14:40:11.888999Z",
     "iopub.status.busy": "2025-05-17T14:40:11.888059Z",
     "iopub.status.idle": "2025-05-17T14:40:11.991665Z",
     "shell.execute_reply": "2025-05-17T14:40:11.990891Z",
     "shell.execute_reply.started": "2025-05-17T14:40:11.888958Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_labels(label_str):\n",
    "    \"\"\"–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç—Ä–æ–∫—É —Å –º–µ—Ç–∫–∞–º–∏ –≤ —Å–ø–∏—Å–æ–∫ —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\"\"\"\n",
    "    return [int(x) for x in label_str.split()]\n",
    "\n",
    "train_df['labels'] = train_df['labels'].apply(convert_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b885dd8-7b75-4819-bf39-5a0dbe0c67f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T14:40:12.618470Z",
     "iopub.status.busy": "2025-05-17T14:40:12.617528Z",
     "iopub.status.idle": "2025-05-17T14:40:12.718026Z",
     "shell.execute_reply": "2025-05-17T14:40:12.717269Z",
     "shell.execute_reply.started": "2025-05-17T14:40:12.618431Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–§–æ—Ä–º–∞ –º–∞—Ç—Ä–∏—Ü—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: (29568,)\n",
      "–§–æ—Ä–º–∞ –º–∞—Ç—Ä–∏—Ü—ã –º–µ—Ç–æ–∫: (29568, 2)\n",
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: 2\n",
      "\n",
      "–ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö:\n",
      "–¢–µ–∫—Å—Ç: 15 —è–Ω–≤–∞—Ä—è\n",
      "–î–µ—Ç—Å–∫–∞—è —Ä–∞–∑–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞\n",
      "15-00 –±–µ—Å–ø–ª–∞—Ç–Ω–æ\n",
      "‚ùóÔ∏è\n",
      "@\n",
      "cafeotdyh\n",
      "–ö–∞—Ñ–µ \"–û—Ç–¥—ã—Ö\"\n",
      "üìç\n",
      "–ó–∞–ø–∏—Å—å –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ +73472228532\n",
      "–ú–µ—Ç–∫–∏: [1 1]\n",
      "–ò–º–µ–Ω–∞ –∫–ª–∞—Å—Å–æ–≤: [0 1]\n"
     ]
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(train_df['labels'])\n",
    "num_classes = y.shape[1]\n",
    "\n",
    "X = train_df['text']\n",
    "y = y  # –ú–∞—Ç—Ä–∏—Ü–∞ –º–µ—Ç–æ–∫\n",
    "\n",
    "print(\"–§–æ—Ä–º–∞ –º–∞—Ç—Ä–∏—Ü—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:\", X.shape)\n",
    "print(\"–§–æ—Ä–º–∞ –º–∞—Ç—Ä–∏—Ü—ã –º–µ—Ç–æ–∫:\", y.shape)\n",
    "print(\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤:\", num_classes)\n",
    "print(\"\\n–ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö:\")\n",
    "print(\"–¢–µ–∫—Å—Ç:\", X.iloc[0])\n",
    "print(\"–ú–µ—Ç–∫–∏:\", y[0])\n",
    "print(\"–ò–º–µ–Ω–∞ –∫–ª–∞—Å—Å–æ–≤:\", mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "564cecd6-61b7-4ac2-bf49-1b88c8b8454c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T14:40:20.136792Z",
     "iopub.status.busy": "2025-05-17T14:40:20.135865Z",
     "iopub.status.idle": "2025-05-17T14:40:20.667159Z",
     "shell.execute_reply": "2025-05-17T14:40:20.666472Z",
     "shell.execute_reply.started": "2025-05-17T14:40:20.136752Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü—Ä–∏–º–µ—Ä –æ—á–∏—â–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞:\n",
      "15 —è–Ω–≤–∞—Ä—è –î–µ—Ç—Å–∫–∞—è —Ä–∞–∑–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞ 15-00 –±–µ—Å–ø–ª–∞—Ç–Ω–æ ‚ùóÔ∏è @ cafeotdyh –ö–∞—Ñ–µ \"–û—Ç–¥—ã—Ö\" üìç –ó–∞–ø–∏—Å—å –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ +73472228532\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "train_df['cleaned_text'] = train_df['text'].apply(clean_text)\n",
    "test_df['cleaned_text'] = test_df['text'].apply(clean_text)\n",
    "\n",
    "print(\"–ü—Ä–∏–º–µ—Ä –æ—á–∏—â–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞:\")\n",
    "print(train_df['cleaned_text'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5593fb9-1efe-458a-844d-ea6436a074a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T14:40:21.394742Z",
     "iopub.status.busy": "2025-05-17T14:40:21.393666Z",
     "iopub.status.idle": "2025-05-17T14:40:21.791186Z",
     "shell.execute_reply": "2025-05-17T14:40:21.790461Z",
     "shell.execute_reply.started": "2025-05-17T14:40:21.394698Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –º–µ—Ç–æ–∫\n",
    "label_counts = pd.Series(y.sum(axis=0), \n",
    "                        index=[f'Class_{i}' for i in range(y.shape[1])])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "label_counts.sort_values().plot(kind='barh', color='skyblue')\n",
    "plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–µ—Ç–æ–∫ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ')\n",
    "plt.xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤')\n",
    "plt.ylabel('–ö–ª–∞—Å—Å—ã')\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c55de27f-9e51-42e8-992d-82d2d5f2b913",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T14:40:25.031127Z",
     "iopub.status.busy": "2025-05-17T14:40:25.030270Z",
     "iopub.status.idle": "2025-05-17T14:40:25.243029Z",
     "shell.execute_reply": "2025-05-17T14:40:25.242314Z",
     "shell.execute_reply.started": "2025-05-17T14:40:25.031100Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# –ê–Ω–∞–ª–∏–∑ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–æ–≤\n",
    "train_df['text_length'] = train_df['text'].apply(len)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(train_df['text_length'], bins=50, color='lightgreen')\n",
    "plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–æ–≤')\n",
    "plt.xlabel('–î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ (—Å–∏–º–≤–æ–ª—ã)')\n",
    "plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cf326f-6511-428f-b8cd-2f7cb651c3ee",
   "metadata": {},
   "source": [
    "# TF-IDF + –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b079ef4d-2faf-441c-9d93-b6a4f474dc9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T14:41:53.296515Z",
     "iopub.status.busy": "2025-05-17T14:41:53.295557Z",
     "iopub.status.idle": "2025-05-17T14:42:00.633140Z",
     "shell.execute_reply": "2025-05-17T14:42:00.632412Z",
     "shell.execute_reply.started": "2025-05-17T14:41:53.296473Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/jupyter/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')  # –û—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è word_tokenize\n",
    "nltk.download('punkt_tab')  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏\n",
    "nltk.download('stopwords')  # –î–ª—è –±—É–¥—É—â–µ–π –æ—á–∏—Å—Ç–∫–∏ –æ—Ç —Å—Ç–æ–ø-—Å–ª–æ–≤\n",
    "nltk.download('wordnet')  # –î–ª—è –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3588de03-fef0-4f49-b50d-ad6a7e98f0e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T14:42:06.145086Z",
     "iopub.status.busy": "2025-05-17T14:42:06.144209Z",
     "iopub.status.idle": "2025-05-17T14:42:17.126656Z",
     "shell.execute_reply": "2025-05-17T14:42:17.125929Z",
     "shell.execute_reply.started": "2025-05-17T14:42:06.145058Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tfidf_clean(text):\n",
    "    # –£–¥–∞–ª–µ–Ω–∏–µ URL, –¥–∞—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, \"13 —è–Ω–≤–∞—Ä—è\"), —ç–º–æ–¥–∑–∏\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+|[\\d]{1,2}\\s*[–∞-—è–ê-–Ø]+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'[^\\w\\s]|[\\U0001F600-\\U0001F64F]', '', text)  # –≠–º–æ–¥–∑–∏ –∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏—è\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤ –∏ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è\n",
    "    stop_words = set(stopwords.words('russian'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "train_df['cleaned_tfidf'] = train_df['text'].apply(tfidf_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4664ecbf-f0c8-40db-8b84-b24af39fb755",
   "metadata": {},
   "source": [
    "# Word2Vec + –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3fd7a346-13fd-4f4a-8629-4d69d0ca09bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:35:19.996647Z",
     "iopub.status.busy": "2025-05-17T15:35:19.995605Z",
     "iopub.status.idle": "2025-05-17T15:35:41.485093Z",
     "shell.execute_reply": "2025-05-17T15:35:41.484442Z",
     "shell.execute_reply.started": "2025-05-17T15:35:19.996616Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "def w2v_clean(text):\n",
    "    # –£–¥–∞–ª–µ–Ω–∏–µ URL –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ (–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    text = re.sub(r'[\\d]{1,2}\\s*[–∞-—è–ê-–Ø]+', '', text)  # –î–∞—Ç—ã\n",
    "    \n",
    "    # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –±–µ–∑ —É–¥–∞–ª–µ–Ω–∏—è —Å—Ç–æ–ø-—Å–ª–æ–≤ (–¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token.isalpha()]  # –¢–æ–ª—å–∫–æ —Å–ª–æ–≤–∞\n",
    "    \n",
    "    return ' '.join(tokens) \n",
    "\n",
    "train_df['cleaned_w2v'] = train_df['text'].apply(w2v_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1ea796-8068-45ee-9baf-8055397a3d34",
   "metadata": {},
   "source": [
    "# CNN —Å–æ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cc10af3a-4790-4a98-a92a-8fb646908aa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:35:49.489195Z",
     "iopub.status.busy": "2025-05-17T15:35:49.488023Z",
     "iopub.status.idle": "2025-05-17T15:36:11.021957Z",
     "shell.execute_reply": "2025-05-17T15:36:11.021114Z",
     "shell.execute_reply.started": "2025-05-17T15:35:49.489146Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cnn_clean(text):\n",
    "    # –£–¥–∞–ª–µ–Ω–∏–µ URL, –Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ –∏ —á–∏—Å–µ–ª\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    text = re.sub(r'[\\U0001F600-\\U0001F64F]', '', text)  # –¢–æ–ª—å–∫–æ —ç–º–æ–¥–∑–∏\n",
    "    \n",
    "    # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ –¥–ª—è n-–≥—Ä–∞–º–º\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in ['¬´', '¬ª', '...']]  # –ß–∞—Å—Ç—ã–µ \"–º—É—Å–æ—Ä–Ω—ã–µ\" —Å–∏–º–≤–æ–ª—ã\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "train_df['cleaned_cnn'] = train_df['text'].apply(cnn_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0512d526-05e9-400f-9c8b-f35f6b6b7b16",
   "metadata": {},
   "source": [
    "# RNN —Å–æ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c806e6fe-bc10-4d5e-98e9-d8dfe66af411",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:36:31.100032Z",
     "iopub.status.busy": "2025-05-17T15:36:31.098929Z",
     "iopub.status.idle": "2025-05-17T15:36:51.298237Z",
     "shell.execute_reply": "2025-05-17T15:36:51.297399Z",
     "shell.execute_reply.started": "2025-05-17T15:36:31.099987Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rnn_clean(text):\n",
    "    # –£–¥–∞–ª–µ–Ω–∏–µ URL –∏ –¥–∞—Ç\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+|[\\d]{1,2}\\s*[–∞-—è–ê-–Ø]+', '', text)\n",
    "    \n",
    "    # –£–¥–∞–ª–µ–Ω–∏–µ —Ä–µ–¥–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤, –Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏\n",
    "    text = re.sub(r'[^\\w\\s.,!?]', '', text)\n",
    "    \n",
    "    # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –¥–ª–∏–Ω—ã\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = tokens[:100]  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã –¥–ª—è RNN\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "train_df['cleaned_rnn'] = train_df['text'].apply(rnn_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ec2ca7-70b3-4927-99c5-e1a0141b213d",
   "metadata": {},
   "source": [
    "# LLaMa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6538850f-35d4-401b-9dcb-1d8c96107ab4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T14:47:23.927072Z",
     "iopub.status.busy": "2025-05-17T14:47:23.926085Z",
     "iopub.status.idle": "2025-05-17T14:47:24.593533Z",
     "shell.execute_reply": "2025-05-17T14:47:24.592780Z",
     "shell.execute_reply.started": "2025-05-17T14:47:23.927031Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def llama_clean(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '[URL]', text)  # –ó–∞–º–µ–Ω–∞ URL –Ω–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω\n",
    "    text = re.sub(r'[\\d]{1,2}\\s*[–∞-—è–ê-–Ø]+', '[DATE]', text)    # –î–∞—Ç—ã\n",
    "    return text.strip()  # –ë–µ–∑ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏!\n",
    "\n",
    "train_df['cleaned_llama'] = train_df['text'].apply(llama_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc6f243-96a8-4b16-bad2-e9bb2df55bc1",
   "metadata": {},
   "source": [
    "# –ü–∞–π–ø–ª–∞–π–Ω"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "24a1b3cc-39d1-40f5-82f4-21133f19ed03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:36:57.488208Z",
     "iopub.status.busy": "2025-05-17T15:36:57.487182Z",
     "iopub.status.idle": "2025-05-17T15:38:29.510769Z",
     "shell.execute_reply": "2025-05-17T15:38:29.509922Z",
     "shell.execute_reply.started": "2025-05-17T15:36:57.488167Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'tfidf': tfidf_clean,\n",
    "    'w2v': w2v_clean,\n",
    "    'cnn': cnn_clean,\n",
    "    'rnn': rnn_clean,\n",
    "    'llama': llama_clean\n",
    "}\n",
    "\n",
    "for name, pipeline in pipelines.items():\n",
    "    train_df[f'cleaned_{name}'] = train_df['text'].apply(pipeline)\n",
    "    test_df[f'cleaned_{name}'] = test_df['text'].apply(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6bc88bf8-d6c5-4aaf-b368-3d53fcdafbee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T14:49:18.241434Z",
     "iopub.status.busy": "2025-05-17T14:49:18.240430Z",
     "iopub.status.idle": "2025-05-17T14:49:18.329670Z",
     "shell.execute_reply": "2025-05-17T14:49:18.328963Z",
     "shell.execute_reply.started": "2025-05-17T14:49:18.241404Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  ...                                      cleaned_llama\n",
      "0   0  ...  [DATE]\\n–î–µ—Ç—Å–∫–∞—è —Ä–∞–∑–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞\\n15-...\n",
      "1   1  ...    [DATE] [DATE]\\n–í—ã—Ö–æ–¥–Ω—ã–µ –≤ –ú–µ–≥–µ\\n[URL]\\n–ú–µ–≥–∞–ø–∞—Ä–∫\n",
      "2   2  ...  –ô–æ–∫–Ω–∞–ø–∞—Ç–æ—Ñ–∞\\n–ü–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –¢–µ–∞—Ç—Ä –∏–º. –ú–∞—è–∫–æ–≤—Å–∫–æ–≥–æ\\...\n",
      "3   3  ...  –í–ø–µ—Ä–≤—ã–µ –≤ –£—Ñ–µ —Ç–∞–Ω—Ü–µ–≤–∞–ª—å–Ω–∞—è —Ç–µ—Ä–∞–ø–∏—è –≤ –≥—Ä—É–ø–ø–µ —Å ...\n",
      "4   4  ...  üéπ\\nGRAND PIANO COMPETITION\\nüéπ\\n–î—Ä—É–∑—å—è, —Å–µ–≥–æ–¥–Ω—è...\n",
      "\n",
      "[5 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c3d09a8-4509-493d-bb2c-40e1202c6cfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T14:49:38.503892Z",
     "iopub.status.busy": "2025-05-17T14:49:38.502852Z",
     "iopub.status.idle": "2025-05-17T14:49:38.646698Z",
     "shell.execute_reply": "2025-05-17T14:49:38.645788Z",
     "shell.execute_reply.started": "2025-05-17T14:49:38.503846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'text', 'labels', 'cleaned_text', 'text_length', 'cleaned_tfidf',\n",
       "       'cleaned_w2v', 'cleaned_cnn', 'cleaned_rnn', 'cleaned_llama'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e4dfdd-5246-4106-862f-cad4c9457d54",
   "metadata": {},
   "source": [
    "# –û–±—É—á–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b419d0d-c1f1-4f1c-8cf2-7c9731cf8234",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T14:49:42.211568Z",
     "iopub.status.busy": "2025-05-17T14:49:42.210612Z",
     "iopub.status.idle": "2025-05-17T14:49:42.229409Z",
     "shell.execute_reply": "2025-05-17T14:49:42.228770Z",
     "shell.execute_reply.started": "2025-05-17T14:49:42.211526Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_callbacks(model_name):\n",
    "    return [\n",
    "        EarlyStopping(patience=3, monitor='val_loss', restore_best_weights=True),\n",
    "        ModelCheckpoint(f'best_{model_name}.h5', save_best_only=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2),\n",
    "        LearningRateScheduler(lambda epoch, lr: lr * 0.95 if epoch > 5 else lr)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a60aac7-938c-491b-a787-b4ed6b00c18c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T14:49:43.540394Z",
     "iopub.status.busy": "2025-05-17T14:49:43.539398Z",
     "iopub.status.idle": "2025-05-17T14:49:43.568853Z",
     "shell.execute_reply": "2025-05-17T14:49:43.568177Z",
     "shell.execute_reply.started": "2025-05-17T14:49:43.540355Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def macro_f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true * y_pred, 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true) * y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true * (1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "    macro_f1 = K.mean(f1)\n",
    "    return macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a582449-5428-4a6f-ba84-10d74ef39f72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T14:52:00.575134Z",
     "iopub.status.busy": "2025-05-17T14:52:00.574168Z",
     "iopub.status.idle": "2025-05-17T14:52:00.697818Z",
     "shell.execute_reply": "2025-05-17T14:52:00.696969Z",
     "shell.execute_reply.started": "2025-05-17T14:52:00.575092Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def labels_to_matrix(labels_series):\n",
    "    \"\"\"\n",
    "    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ø–∏—Å–∫–æ–≤ –≤ numpy array\n",
    "    (—É–∂–µ –Ω–µ –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å split, —Ç–∞–∫ –∫–∞–∫ –¥–∞–Ω–Ω—ã–µ —É–∂–µ –≤ –≤–∏–¥–µ —Å–ø–∏—Å–∫–æ–≤)\n",
    "    \"\"\"\n",
    "    return np.array([list(map(int, lst)) for lst in labels_series])\n",
    "\n",
    "labels = labels_to_matrix(train_df['labels'])\n",
    "X = train_df\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfee066a-6794-4d86-9a0f-488e3de0977a",
   "metadata": {},
   "source": [
    "## TF-IDF + –ù–ù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "da232c18-0d63-4eed-999a-f00805f456c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T20:34:24.961553Z",
     "iopub.status.busy": "2025-05-17T20:34:24.960461Z",
     "iopub.status.idle": "2025-05-17T20:35:05.984943Z",
     "shell.execute_reply": "2025-05-17T20:35:05.984022Z",
     "shell.execute_reply.started": "2025-05-17T20:34:24.961509Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TF-IDF + NN...\n",
      "Epoch 1/20\n",
      "365/370 [============================>.] - ETA: 0s - loss: 0.3135 - accuracy: 0.0085 - macro_f1: 0.6915"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 7s 15ms/step - loss: 0.3125 - accuracy: 0.0087 - macro_f1: 0.6922 - val_loss: 0.2273 - val_accuracy: 0.0157 - val_macro_f1: 0.7511 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "365/370 [============================>.] - ETA: 0s - loss: 0.1959 - accuracy: 0.0182 - macro_f1: 0.7748"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 5s 14ms/step - loss: 0.1958 - accuracy: 0.0183 - macro_f1: 0.7748 - val_loss: 0.2037 - val_accuracy: 0.0162 - val_macro_f1: 0.7753 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "365/370 [============================>.] - ETA: 0s - loss: 0.1545 - accuracy: 0.0165 - macro_f1: 0.8088"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 5s 14ms/step - loss: 0.1545 - accuracy: 0.0164 - macro_f1: 0.8085 - val_loss: 0.1995 - val_accuracy: 0.0162 - val_macro_f1: 0.7915 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "370/370 [==============================] - 2s 5ms/step - loss: 0.1263 - accuracy: 0.0168 - macro_f1: 0.8304 - val_loss: 0.2057 - val_accuracy: 0.0149 - val_macro_f1: 0.7939 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "370/370 [==============================] - 2s 5ms/step - loss: 0.1059 - accuracy: 0.0176 - macro_f1: 0.8467 - val_loss: 0.2119 - val_accuracy: 0.0162 - val_macro_f1: 0.7937 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "370/370 [==============================] - 2s 5ms/step - loss: 0.0810 - accuracy: 0.0195 - macro_f1: 0.8660 - val_loss: 0.2129 - val_accuracy: 0.0178 - val_macro_f1: 0.8007 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "print(\"Training TF-IDF + NN...\")\n",
    "tfidf = TfidfVectorizer(max_features=10000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train['text'].apply(tfidf_clean))\n",
    "X_val_tfidf = tfidf.transform(X_val['text'].apply(tfidf_clean))\n",
    "\n",
    "tfidf_nn = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(X_train_tfidf.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(labels.shape[1], activation='sigmoid')\n",
    "])\n",
    "\n",
    "tfidf_nn.compile(\n",
    "    optimizer=Adam(0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', macro_f1]\n",
    ")\n",
    "\n",
    "history_tfidf = tfidf_nn.fit(\n",
    "    X_train_tfidf.toarray(), y_train,\n",
    "    validation_data=(X_val_tfidf.toarray(), y_val),\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    callbacks=get_callbacks('tfidf_nn')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e946458f-49f9-4ef1-9fc5-502dc99ea8c1",
   "metadata": {},
   "source": [
    "## Word2Vec + HH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dcc8d638-fd0e-4f7a-921c-db3c041adde2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:05:50.375012Z",
     "iopub.status.busy": "2025-05-17T15:05:50.373880Z",
     "iopub.status.idle": "2025-05-17T15:07:12.665884Z",
     "shell.execute_reply": "2025-05-17T15:07:12.665039Z",
     "shell.execute_reply.started": "2025-05-17T15:05:50.374963Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec...\n",
      "Creating embeddings...\n",
      "Building NN model...\n",
      "Training NN...\n",
      "Epoch 1/20\n",
      "353/370 [===========================>..] - ETA: 0s - loss: 0.4352 - accuracy: 0.0254 - macro_f1: 0.6587"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 2s 3ms/step - loss: 0.4333 - accuracy: 0.0257 - macro_f1: 0.6598 - val_loss: 0.3805 - val_accuracy: 0.0299 - val_macro_f1: 0.6909 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "370/370 [==============================] - 1s 3ms/step - loss: 0.3754 - accuracy: 0.0259 - macro_f1: 0.6935 - val_loss: 0.3495 - val_accuracy: 0.0340 - val_macro_f1: 0.7099 - lr: 0.0010\n",
      "Epoch 3/20\n",
      " 22/370 [>.............................] - ETA: 0s - loss: 0.3616 - accuracy: 0.0348 - macro_f1: 0.6994"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 1s 3ms/step - loss: 0.3551 - accuracy: 0.0274 - macro_f1: 0.7063 - val_loss: 0.3377 - val_accuracy: 0.0232 - val_macro_f1: 0.7130 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "  1/370 [..............................] - ETA: 1s - loss: 0.3634 - accuracy: 0.0312 - macro_f1: 0.7080"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 1s 3ms/step - loss: 0.3427 - accuracy: 0.0274 - macro_f1: 0.7139 - val_loss: 0.3255 - val_accuracy: 0.0309 - val_macro_f1: 0.7248 - lr: 0.0010\n",
      "Epoch 5/20\n",
      " 43/370 [==>...........................] - ETA: 0s - loss: 0.3366 - accuracy: 0.0211 - macro_f1: 0.7158"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 1s 3ms/step - loss: 0.3353 - accuracy: 0.0276 - macro_f1: 0.7175 - val_loss: 0.3173 - val_accuracy: 0.0338 - val_macro_f1: 0.7266 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "  1/370 [..............................] - ETA: 1s - loss: 0.3214 - accuracy: 0.0156 - macro_f1: 0.7274"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 1s 3ms/step - loss: 0.3301 - accuracy: 0.0279 - macro_f1: 0.7208 - val_loss: 0.3115 - val_accuracy: 0.0330 - val_macro_f1: 0.7338 - lr: 0.0010\n",
      "Epoch 7/20\n",
      " 43/370 [==>...........................] - ETA: 0s - loss: 0.3270 - accuracy: 0.0262 - macro_f1: 0.7240"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 1s 3ms/step - loss: 0.3233 - accuracy: 0.0276 - macro_f1: 0.7251 - val_loss: 0.3068 - val_accuracy: 0.0238 - val_macro_f1: 0.7336 - lr: 9.5000e-04\n",
      "Epoch 8/20\n",
      "  1/370 [..............................] - ETA: 1s - loss: 0.3072 - accuracy: 0.0469 - macro_f1: 0.7507"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/370 [============================>.] - ETA: 0s - loss: 0.3204 - accuracy: 0.0275 - macro_f1: 0.7264"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 1s 3ms/step - loss: 0.3201 - accuracy: 0.0276 - macro_f1: 0.7264 - val_loss: 0.3041 - val_accuracy: 0.0208 - val_macro_f1: 0.7364 - lr: 9.0250e-04\n",
      "Epoch 9/20\n",
      "370/370 [==============================] - 1s 3ms/step - loss: 0.3170 - accuracy: 0.0266 - macro_f1: 0.7281 - val_loss: 0.3005 - val_accuracy: 0.0265 - val_macro_f1: 0.7373 - lr: 8.5737e-04\n",
      "Epoch 10/20\n",
      " 22/370 [>.............................] - ETA: 0s - loss: 0.3144 - accuracy: 0.0206 - macro_f1: 0.7271"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359/370 [============================>.] - ETA: 0s - loss: 0.3130 - accuracy: 0.0288 - macro_f1: 0.7306"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 1s 3ms/step - loss: 0.3134 - accuracy: 0.0287 - macro_f1: 0.7302 - val_loss: 0.2983 - val_accuracy: 0.0228 - val_macro_f1: 0.7353 - lr: 8.1451e-04\n",
      "Epoch 11/20\n",
      "370/370 [==============================] - 1s 3ms/step - loss: 0.3108 - accuracy: 0.0287 - macro_f1: 0.7313 - val_loss: 0.2960 - val_accuracy: 0.0223 - val_macro_f1: 0.7363 - lr: 7.7378e-04\n",
      "Epoch 12/20\n",
      "  1/370 [..............................] - ETA: 1s - loss: 0.3126 - accuracy: 0.0625 - macro_f1: 0.7253"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 1s 3ms/step - loss: 0.3093 - accuracy: 0.0293 - macro_f1: 0.7317 - val_loss: 0.2939 - val_accuracy: 0.0306 - val_macro_f1: 0.7416 - lr: 7.3509e-04\n",
      "Epoch 13/20\n",
      " 22/370 [>.............................] - ETA: 0s - loss: 0.3067 - accuracy: 0.0241 - macro_f1: 0.7340"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 1s 3ms/step - loss: 0.3056 - accuracy: 0.0306 - macro_f1: 0.7341 - val_loss: 0.2942 - val_accuracy: 0.0294 - val_macro_f1: 0.7383 - lr: 6.9834e-04\n",
      "Epoch 14/20\n",
      "370/370 [==============================] - 1s 3ms/step - loss: 0.3052 - accuracy: 0.0320 - macro_f1: 0.7336 - val_loss: 0.2908 - val_accuracy: 0.0357 - val_macro_f1: 0.7423 - lr: 6.6342e-04\n",
      "Epoch 15/20\n",
      " 43/370 [==>...........................] - ETA: 0s - loss: 0.3029 - accuracy: 0.0360 - macro_f1: 0.7375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 1s 3ms/step - loss: 0.3035 - accuracy: 0.0327 - macro_f1: 0.7357 - val_loss: 0.2883 - val_accuracy: 0.0372 - val_macro_f1: 0.7453 - lr: 6.3025e-04\n",
      "Epoch 16/20\n",
      "  1/370 [..............................] - ETA: 1s - loss: 0.3023 - accuracy: 0.0625 - macro_f1: 0.7252"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 1s 3ms/step - loss: 0.3017 - accuracy: 0.0349 - macro_f1: 0.7361 - val_loss: 0.2868 - val_accuracy: 0.0384 - val_macro_f1: 0.7422 - lr: 5.9874e-04\n",
      "Epoch 17/20\n",
      " 43/370 [==>...........................] - ETA: 0s - loss: 0.2971 - accuracy: 0.0316 - macro_f1: 0.7393"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358/370 [============================>.] - ETA: 0s - loss: 0.2997 - accuracy: 0.0347 - macro_f1: 0.7375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 1s 3ms/step - loss: 0.3002 - accuracy: 0.0344 - macro_f1: 0.7372 - val_loss: 0.2863 - val_accuracy: 0.0367 - val_macro_f1: 0.7452 - lr: 5.6880e-04\n",
      "Epoch 18/20\n",
      "370/370 [==============================] - 1s 3ms/step - loss: 0.2986 - accuracy: 0.0348 - macro_f1: 0.7369 - val_loss: 0.2849 - val_accuracy: 0.0377 - val_macro_f1: 0.7465 - lr: 5.4036e-04\n",
      "Epoch 19/20\n",
      " 22/370 [>.............................] - ETA: 0s - loss: 0.2911 - accuracy: 0.0362 - macro_f1: 0.7405"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 1s 3ms/step - loss: 0.2975 - accuracy: 0.0349 - macro_f1: 0.7376 - val_loss: 0.2857 - val_accuracy: 0.0375 - val_macro_f1: 0.7435 - lr: 5.1334e-04\n",
      "Epoch 20/20\n",
      "370/370 [==============================] - 1s 3ms/step - loss: 0.2968 - accuracy: 0.0360 - macro_f1: 0.7389 - val_loss: 0.2855 - val_accuracy: 0.0370 - val_macro_f1: 0.7418 - lr: 4.8767e-05\n"
     ]
    }
   ],
   "source": [
    "sentences = X_train['text'].tolist()\n",
    "\n",
    "print(\"Training Word2Vec...\")\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=sentences,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    workers=4,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "class W2VEmbedding:\n",
    "    def __init__(self, w2v_model):\n",
    "        self.w2v = w2v_model\n",
    "\n",
    "    def embed(self, texts):\n",
    "        embeddings = []\n",
    "        for text in texts:\n",
    "            # –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –ø–æ–ª—É—á–∞–µ–º –≤–µ–∫—Ç–æ—Ä–∞ —Å–ª–æ–≤ –∏ —É—Å—Ä–µ–¥–Ω—è–µ–º\n",
    "            word_vectors = [self.w2v.wv[word] for word in text if word in self.w2v.wv]\n",
    "            if len(word_vectors) == 0:\n",
    "                embeddings.append(np.zeros(100))\n",
    "            else:\n",
    "                embeddings.append(np.mean(word_vectors, axis=0))\n",
    "        return np.array(embeddings)\n",
    "\n",
    "print(\"Creating embeddings...\")\n",
    "embedder = W2VEmbedding(w2v_model)\n",
    "X_train_w2v = embedder.embed(X_train['text'])\n",
    "X_val_w2v = embedder.embed(X_val['text'])\n",
    "\n",
    "print(\"Building NN model...\")\n",
    "w2v_nn = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(100,)),\n",
    "    Dropout(0.5),\n",
    "    Dense(labels.shape[1], activation='sigmoid')\n",
    "])\n",
    "\n",
    "w2v_nn.compile(\n",
    "    optimizer=Adam(0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', macro_f1]\n",
    ")\n",
    "\n",
    "print(\"Training NN...\")\n",
    "history = w2v_nn.fit(\n",
    "    X_train_w2v, y_train,\n",
    "    validation_data=(X_val_w2v, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    callbacks=get_callbacks('w2v_nn')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b137a9b7-c4f6-400b-802c-6cd0cb0cb776",
   "metadata": {},
   "source": [
    "## CNN —Å–æ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e698f337-c624-4fff-9b01-7788c39cba94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:46:39.193761Z",
     "iopub.status.busy": "2025-05-17T15:46:39.192688Z",
     "iopub.status.idle": "2025-05-17T15:48:24.216219Z",
     "shell.execute_reply": "2025-05-17T15:48:24.215493Z",
     "shell.execute_reply.started": "2025-05-17T15:46:39.193718Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CNN with Embedding...\n",
      "Epoch 1/20\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.3208 - accuracy: 0.0144 - macro_f1: 0.6882"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 31s 63ms/step - loss: 0.3208 - accuracy: 0.0144 - macro_f1: 0.6882 - val_loss: 0.2420 - val_accuracy: 0.0188 - val_macro_f1: 0.7417 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.2057 - accuracy: 0.0184 - macro_f1: 0.7608"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 9s 26ms/step - loss: 0.2057 - accuracy: 0.0184 - macro_f1: 0.7608 - val_loss: 0.2012 - val_accuracy: 0.0169 - val_macro_f1: 0.7692 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.1591 - accuracy: 0.0182 - macro_f1: 0.7936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 6s 17ms/step - loss: 0.1591 - accuracy: 0.0182 - macro_f1: 0.7936 - val_loss: 0.1846 - val_accuracy: 0.0166 - val_macro_f1: 0.7793 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.1241 - accuracy: 0.0178 - macro_f1: 0.8193"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 4s 11ms/step - loss: 0.1241 - accuracy: 0.0178 - macro_f1: 0.8193 - val_loss: 0.1777 - val_accuracy: 0.0154 - val_macro_f1: 0.7923 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "370/370 [==============================] - 3s 9ms/step - loss: 0.0955 - accuracy: 0.0186 - macro_f1: 0.8416 - val_loss: 0.1777 - val_accuracy: 0.0159 - val_macro_f1: 0.7944 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "370/370 [==============================] - 3s 9ms/step - loss: 0.0725 - accuracy: 0.0177 - macro_f1: 0.8610 - val_loss: 0.1845 - val_accuracy: 0.0161 - val_macro_f1: 0.7978 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "370/370 [==============================] - 3s 7ms/step - loss: 0.0507 - accuracy: 0.0182 - macro_f1: 0.8795 - val_loss: 0.1811 - val_accuracy: 0.0161 - val_macro_f1: 0.8012 - lr: 9.5000e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"Training CNN with Embedding...\")\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train['text'].apply(cnn_clean))\n",
    "\n",
    "X_train_cnn = pad_sequences(\n",
    "    tokenizer.texts_to_sequences(X_train['text'].apply(cnn_clean)),\n",
    "    maxlen=100,\n",
    "    padding='post'\n",
    ")\n",
    "X_val_cnn = pad_sequences(\n",
    "    tokenizer.texts_to_sequences(X_val['text'].apply(cnn_clean)),\n",
    "    maxlen=100,\n",
    "    padding='post'\n",
    ")\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Embedding(10000, 128, input_length=100),\n",
    "    Conv1D(128, 5, activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(labels.shape[1], activation='sigmoid')\n",
    "])\n",
    "\n",
    "cnn_model.compile(\n",
    "    optimizer=Adam(0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', macro_f1]\n",
    ")\n",
    "\n",
    "history_cnn = cnn_model.fit(\n",
    "    X_train_cnn, y_train,\n",
    "    validation_data=(X_val_cnn, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    callbacks=get_callbacks('cnn_model')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879a5b69-e03a-4e7c-858b-82a81596b0fc",
   "metadata": {},
   "source": [
    "## RNN —Å–æ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9aecc17b-a817-4d73-a767-9dd40d2b845c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:59:48.186766Z",
     "iopub.status.busy": "2025-05-17T15:59:48.185712Z",
     "iopub.status.idle": "2025-05-17T16:01:41.996573Z",
     "shell.execute_reply": "2025-05-17T16:01:41.995605Z",
     "shell.execute_reply.started": "2025-05-17T15:59:48.186732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RNN with Embedding...\n",
      "Epoch 1/20\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.3511 - accuracy: 0.0052 - macro_f1: 0.6673"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 29s 68ms/step - loss: 0.3511 - accuracy: 0.0052 - macro_f1: 0.6673 - val_loss: 0.2884 - val_accuracy: 0.0042 - val_macro_f1: 0.7165 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.2588 - accuracy: 0.0041 - macro_f1: 0.7339"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 11s 31ms/step - loss: 0.2588 - accuracy: 0.0041 - macro_f1: 0.7339 - val_loss: 0.2526 - val_accuracy: 0.0069 - val_macro_f1: 0.7400 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.2233 - accuracy: 0.0042 - macro_f1: 0.7536"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 8s 21ms/step - loss: 0.2233 - accuracy: 0.0042 - macro_f1: 0.7536 - val_loss: 0.2345 - val_accuracy: 0.0076 - val_macro_f1: 0.7483 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.1958 - accuracy: 0.0043 - macro_f1: 0.7692"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 6s 16ms/step - loss: 0.1958 - accuracy: 0.0043 - macro_f1: 0.7692 - val_loss: 0.2248 - val_accuracy: 0.0059 - val_macro_f1: 0.7601 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "370/370 [==============================] - ETA: 0s - loss: 0.1732 - accuracy: 0.0042 - macro_f1: 0.7826"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 5s 13ms/step - loss: 0.1732 - accuracy: 0.0042 - macro_f1: 0.7826 - val_loss: 0.2184 - val_accuracy: 0.0054 - val_macro_f1: 0.7605 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "370/370 [==============================] - 4s 11ms/step - loss: 0.1530 - accuracy: 0.0041 - macro_f1: 0.7933 - val_loss: 0.2194 - val_accuracy: 0.0056 - val_macro_f1: 0.7630 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "370/370 [==============================] - 5s 13ms/step - loss: 0.1352 - accuracy: 0.0041 - macro_f1: 0.8029 - val_loss: 0.2212 - val_accuracy: 0.0054 - val_macro_f1: 0.7684 - lr: 9.5000e-05\n",
      "Epoch 8/20\n",
      "370/370 [==============================] - 4s 12ms/step - loss: 0.1136 - accuracy: 0.0043 - macro_f1: 0.8147 - val_loss: 0.2218 - val_accuracy: 0.0052 - val_macro_f1: 0.7720 - lr: 9.0250e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"Training RNN with Embedding...\")\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train['text'].apply(rnn_clean))\n",
    "\n",
    "X_train_rnn = pad_sequences(\n",
    "    tokenizer.texts_to_sequences(X_train['text'].apply(rnn_clean)),\n",
    "    maxlen=100,\n",
    "    padding='post',\n",
    "    truncating='post'\n",
    ")\n",
    "\n",
    "X_val_rnn = pad_sequences(\n",
    "    tokenizer.texts_to_sequences(X_val['text'].apply(rnn_clean)),\n",
    "    maxlen=100,\n",
    "    padding='post',\n",
    "    truncating='post'\n",
    ")\n",
    "\n",
    "rnn_model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=128, input_length=100),\n",
    "    Bidirectional(LSTM(64, return_sequences=False)),\n",
    "    Dense(units=labels.shape[1], activation='sigmoid')\n",
    "])\n",
    "\n",
    "rnn_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', macro_f1] \n",
    ")\n",
    "\n",
    "history_rnn = rnn_model.fit(\n",
    "    X_train_rnn, y_train,\n",
    "    validation_data=(X_val_rnn, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    callbacks=get_callbacks('rnn_model')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f816b093-c4a4-4ed2-882a-8f87813a0c66",
   "metadata": {},
   "source": [
    "## LLaMa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "06e5ad8f-bd09-43f7-bf41-ecf27dc89b0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T19:00:07.216088Z",
     "iopub.status.busy": "2025-05-17T19:00:07.215016Z",
     "iopub.status.idle": "2025-05-17T19:00:07.281857Z",
     "shell.execute_reply": "2025-05-17T19:00:07.280975Z",
     "shell.execute_reply.started": "2025-05-17T19:00:07.216050Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1fdf2e8b-86bd-469c-85ee-d9e633ab7559",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T20:20:47.971412Z",
     "iopub.status.busy": "2025-05-17T20:20:47.970302Z",
     "iopub.status.idle": "2025-05-17T20:20:48.011305Z",
     "shell.execute_reply": "2025-05-17T20:20:48.010510Z",
     "shell.execute_reply.started": "2025-05-17T20:20:47.971364Z"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d45bf5bd-4f8e-42b1-bd57-eaf3141ea165",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-17T20:30:43.175361Z",
     "iopub.status.busy": "2025-05-17T20:30:43.174252Z",
     "iopub.status.idle": "2025-05-17T20:30:46.950823Z",
     "shell.execute_reply": "2025-05-17T20:30:46.949962Z",
     "shell.execute_reply.started": "2025-05-17T20:30:43.175320Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from /tmp/xdg_cache/huggingface/hub/models--TheBloke--Mistral-7B-Instruct-v0.2-GGUF/snapshots/3a6fbf4a41a1d52e415a4958cde6856d34b2db93/mistral-7b-instruct-v0.2.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q4_K - Medium\n",
      "print_info: file size   = 4.07 GiB (4.83 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 1\n",
      "load: control token:      2 '</s>' is not marked as EOG\n",
      "load: control token:      1 '<s>' is not marked as EOG\n",
      "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "load: special tokens cache size = 3\n",
      "load: token to piece cache size = 0.1637 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 32768\n",
      "print_info: n_embd           = 4096\n",
      "print_info: n_layer          = 32\n",
      "print_info: n_head           = 32\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: n_swa_pattern    = 1\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 4\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 14336\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 1000000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 32768\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: ssm_d_conv       = 0\n",
      "print_info: ssm_d_inner      = 0\n",
      "print_info: ssm_d_state      = 0\n",
      "print_info: ssm_dt_rank      = 0\n",
      "print_info: ssm_dt_b_c_rms   = 0\n",
      "print_info: model type       = 7B\n",
      "print_info: model params     = 7.24 B\n",
      "print_info: general.name     = mistralai_mistral-7b-instruct-v0.2\n",
      "print_info: vocab type       = SPM\n",
      "print_info: n_vocab          = 32000\n",
      "print_info: n_merges         = 0\n",
      "print_info: BOS token        = 1 '<s>'\n",
      "print_info: EOS token        = 2 '</s>'\n",
      "print_info: UNK token        = 0 '<unk>'\n",
      "print_info: PAD token        = 0 '<unk>'\n",
      "print_info: LF token         = 13 '<0x0A>'\n",
      "print_info: EOG token        = 2 '</s>'\n",
      "print_info: max token length = 48\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  29 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  30 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  31 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  32 assigned to device CPU, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (q4_K) (and 98 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "load_tensors:  CPU_AARCH64 model buffer size =  3204.00 MiB\n",
      "load_tensors:   CPU_Mapped model buffer size =  4165.37 MiB\n",
      "repack: repack tensor blk.0.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.0.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.0.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.0.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.0.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.1.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.1.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.1.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.1.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.1.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.2.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.2.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.2.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.2.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.2.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.3.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.3.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.3.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.3.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.3.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.4.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.4.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.4.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.4.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.4.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.4.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.4.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.5.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.5.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.5.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.5.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.5.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.5.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.5.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.6.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.6.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.6.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.6.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.6.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.7.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.7.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.7.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.7.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.7.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.7.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.7.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.8.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.8.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.8.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.8.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.8.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.8.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.8.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.9.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.9.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.9.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.9.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.9.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.10.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.10.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.10.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.10.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.10.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.10.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.10.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.11.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.11.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.11.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.11.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.11.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.11.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.11.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.12.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.12.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.12.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.12.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.12.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.13.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.13.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.13.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.14.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.14.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.14.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.14.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.14.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.14.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.14.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.15.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.15.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.15.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.15.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.15.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.16.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.16.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.16.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.16.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.16.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.16.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.16.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.17.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.17.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.17.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.17.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.17.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.17.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.17.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.18.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.18.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.18.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.18.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.18.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.19.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.19.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.19.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.19.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.19.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.19.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.19.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.20.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.20.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.20.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.20.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.20.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.20.ffn_down.weight with q4_K_8x8\n",
      "repack: repack tensor blk.20.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.21.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.21.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.21.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.21.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.21.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.22.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.attn_v.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.22.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.22.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.22.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.23.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.23.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.23.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.23.attn_output.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.23.ffn_gate.weight with q4_K_8x8\n",
      "repack: repack tensor blk.23.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.23.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.24.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.24.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.24.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.24.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.24.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.25.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.25.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.25.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.25.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.25.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.25.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.25.ffn_up.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.26.attn_q.weight with q4_K_8x8\n",
      "repack: repack tensor blk.26.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.26.attn_v.weight with q4_K_8x8\n",
      "repack: repack tensor blk.26.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.26.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.26.ffn_down.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.26.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.27.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.27.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.27.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.27.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.27.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.28.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.28.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.28.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.28.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.28.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.29.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.29.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.29.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.29.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.29.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.30.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.30.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.30.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.30.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.30.ffn_up.weight with q4_K_8x8\n",
      "repack: repack tensor blk.31.attn_q.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.31.attn_k.weight with q4_K_8x8\n",
      "repack: repack tensor blk.31.attn_output.weight with q4_K_8x8\n",
      "repack: repack tensor blk.31.ffn_gate.weight with q4_K_8x8\n",
      ".repack: repack tensor blk.31.ffn_up.weight with q4_K_8x8\n",
      "...................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 2048\n",
      "llama_context: n_ctx_per_seq = 2048\n",
      "llama_context: n_batch       = 512\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: freq_base     = 1000000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (2048) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "set_abort_callback: call\n",
      "llama_context:        CPU  output buffer size =     0.12 MiB\n",
      "create_memory: n_ctx = 2048 (padded)\n",
      "llama_kv_cache_unified: kv_size = 2048, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1, padding = 32\n",
      "llama_kv_cache_unified: layer   0: dev = CPU\n",
      "llama_kv_cache_unified: layer   1: dev = CPU\n",
      "llama_kv_cache_unified: layer   2: dev = CPU\n",
      "llama_kv_cache_unified: layer   3: dev = CPU\n",
      "llama_kv_cache_unified: layer   4: dev = CPU\n",
      "llama_kv_cache_unified: layer   5: dev = CPU\n",
      "llama_kv_cache_unified: layer   6: dev = CPU\n",
      "llama_kv_cache_unified: layer   7: dev = CPU\n",
      "llama_kv_cache_unified: layer   8: dev = CPU\n",
      "llama_kv_cache_unified: layer   9: dev = CPU\n",
      "llama_kv_cache_unified: layer  10: dev = CPU\n",
      "llama_kv_cache_unified: layer  11: dev = CPU\n",
      "llama_kv_cache_unified: layer  12: dev = CPU\n",
      "llama_kv_cache_unified: layer  13: dev = CPU\n",
      "llama_kv_cache_unified: layer  14: dev = CPU\n",
      "llama_kv_cache_unified: layer  15: dev = CPU\n",
      "llama_kv_cache_unified: layer  16: dev = CPU\n",
      "llama_kv_cache_unified: layer  17: dev = CPU\n",
      "llama_kv_cache_unified: layer  18: dev = CPU\n",
      "llama_kv_cache_unified: layer  19: dev = CPU\n",
      "llama_kv_cache_unified: layer  20: dev = CPU\n",
      "llama_kv_cache_unified: layer  21: dev = CPU\n",
      "llama_kv_cache_unified: layer  22: dev = CPU\n",
      "llama_kv_cache_unified: layer  23: dev = CPU\n",
      "llama_kv_cache_unified: layer  24: dev = CPU\n",
      "llama_kv_cache_unified: layer  25: dev = CPU\n",
      "llama_kv_cache_unified: layer  26: dev = CPU\n",
      "llama_kv_cache_unified: layer  27: dev = CPU\n",
      "llama_kv_cache_unified: layer  28: dev = CPU\n",
      "llama_kv_cache_unified: layer  29: dev = CPU\n",
      "llama_kv_cache_unified: layer  30: dev = CPU\n",
      "llama_kv_cache_unified: layer  31: dev = CPU\n",
      "llama_kv_cache_unified:        CPU KV buffer size =   256.00 MiB\n",
      "llama_kv_cache_unified: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 1\n",
      "llama_context: max_nodes = 65536\n",
      "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
      "llama_context: reserving graph for n_tokens = 512, n_seqs = 1\n",
      "llama_context: reserving graph for n_tokens = 1, n_seqs = 1\n",
      "llama_context: reserving graph for n_tokens = 512, n_seqs = 1\n",
      "llama_context:        CPU compute buffer size =   164.01 MiB\n",
      "llama_context: graph nodes  = 1094\n",
      "llama_context: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | AVX512 = 1 | AVX512_VBMI = 1 | AVX512_VNNI = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '1000000.000000', 'llama.context_length': '32768', 'general.name': 'mistralai_mistral-7b-instruct-v0.2', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Guessed chat format: mistral-instruct\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(X.join(pd.DataFrame(labels, columns=[f\"label_{i}\" for i in range(labels.shape[1])])), \n",
    "                                    test_size=0.2, random_state=42)\n",
    "\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=\"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\",\n",
    "    filename=\"mistral-7b-instruct-v0.2.Q4_K_M.gguf\",  # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç\n",
    "    resume_download=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"TheBloke/Mistral-7B-Instruct-v0.2-AWQ\")\n",
    "\n",
    "model = Llama(\n",
    "    model_path=model_path,\n",
    "    n_ctx=2048,  # –†–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\n",
    "    n_threads=8  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ CPU-–ø–æ—Ç–æ–∫–æ–≤\n",
    ")\n",
    "\n",
    "class LlamaClassificationDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=512):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        text = row['cleaned_llama']\n",
    "        labels = row['labels']\n",
    "        \n",
    "        prompt = f\"\"\"<s>[INST] Classify this text: {text} [/INST]\"\"\"\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            prompt,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.FloatTensor(labels)\n",
    "        }\n",
    "\n",
    "train_dataset = LlamaClassificationDataset(train_df, tokenizer)\n",
    "val_dataset = LlamaClassificationDataset(val_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "394665c9-237f-4404-ab6c-a2f3880c1660",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T20:19:06.062202Z",
     "iopub.status.busy": "2025-05-17T20:19:06.061231Z",
     "iopub.status.idle": "2025-05-17T20:19:06.104806Z",
     "shell.execute_reply": "2025-05-17T20:19:06.103928Z",
     "shell.execute_reply.started": "2025-05-17T20:19:06.062164Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps, last_epoch=-1):\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        return max(\n",
    "            0.0, float(num_training_steps - current_step) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "        )\n",
    "    return LambdaLR(optimizer, lr_lambda, last_epoch)\n",
    "\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.best_metric = -np.inf\n",
    "        self.early_stopping_patience = 3\n",
    "        self.no_improvement_count = 0\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # –°–≤–∏—Ç—á –º–µ–∂–¥—É loss —Ñ—É–Ω–∫—Ü–∏—è–º–∏\n",
    "        loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels),\n",
    "                       labels.float().view(-1, self.model.config.num_labels))\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    def evaluation_step(self, model, inputs):\n",
    "        inputs = self._prepare_inputs(inputs)\n",
    "        with torch.no_grad():\n",
    "            loss, outputs = self.compute_loss(model, inputs, return_outputs=True)\n",
    "        logits = outputs.logits\n",
    "        preds = (torch.sigmoid(logits) > 0.5).int()\n",
    "        return {\"loss\": loss, \"preds\": preds, \"labels\": inputs[\"labels\"]}\n",
    "\n",
    "    def evaluate(self, eval_dataset=None, ignore_keys=None):\n",
    "        eval_output = super().evaluate(eval_dataset, ignore_keys)\n",
    "\n",
    "        preds = torch.cat([x[\"preds\"] for x in eval_output.predictions])\n",
    "        labels = torch.cat([x[\"labels\"] for x in eval_output.predictions])\n",
    "\n",
    "        macro_f1 = f1_score(labels.cpu(), preds.cpu(), average=\"macro\")\n",
    "        accuracy = accuracy_score(labels.cpu(), preds.cpu())\n",
    "\n",
    "        eval_output.metrics.update({\n",
    "            \"eval_macro_f1\": macro_f1,\n",
    "            \"eval_accuracy\": accuracy\n",
    "        })\n",
    "\n",
    "        # –†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ macro F1\n",
    "        if macro_f1 > self.best_metric:\n",
    "            self.best_metric = macro_f1\n",
    "            self.no_improvement_count = 0\n",
    "            self.save_model(os.path.join(self.args.output_dir, \"best_model\"))\n",
    "        else:\n",
    "            self.no_improvement_count += 1\n",
    "            if self.no_improvement_count >= self.early_stopping_patience:\n",
    "                self.control.should_training_stop = True\n",
    "\n",
    "        return eval_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a0251d95-857c-45ac-ae4b-2409f2fb3a43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T20:26:38.004485Z",
     "iopub.status.busy": "2025-05-17T20:26:38.003304Z",
     "iopub.status.idle": "2025-05-17T20:26:39.102080Z",
     "shell.execute_reply": "2025-05-17T20:26:39.101130Z",
     "shell.execute_reply.started": "2025-05-17T20:26:38.004413Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Llama' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6287/726889244.py\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     },\n\u001b[1;32m     44\u001b[0m     optimizers=(None, get_linear_schedule_with_warmup(\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mnum_warmup_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarmup_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mnum_training_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Llama' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "def prepare_prompt(text, labels=None):\n",
    "    labels_str = \" \".join(map(str, labels)) if labels else \"\"\n",
    "    \n",
    "    prompt = f\"\"\"<s>[INST] –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–π —Ç–µ–∫—Å—Ç –ø–æ –º–µ—Ç–∫–∞–º:\n",
    "–¢–µ–∫—Å—Ç: {text}\n",
    "–ú–µ—Ç–∫–∏: {labels_str} [/INST]\"\"\"\n",
    "    return prompt\n",
    "\n",
    "train_prompts = [prepare_prompt(row['text'], row['labels']) \n",
    "                for _, row in train_df.iterrows()]\n",
    "total_steps = len(train_prompts) * 5 // 2  # epochs * len(dataset) // batch_size\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./mistral-finetuned\",\n",
    "#     learning_rate=3e-5,\n",
    "#     num_train_epochs=5,\n",
    "#     per_device_train_batch_size=2,\n",
    "#     per_device_eval_batch_size=2,\n",
    "#     gradient_accumulation_steps=4,\n",
    "#     optim=\"adamw_torch\",\n",
    "#     fp16=True,\n",
    "#     logging_steps=10,\n",
    "#     save_steps=500,\n",
    "#     eval_strategy=\"steps\",\n",
    "#     eval_steps=100,\n",
    "#     load_best_model_at_end=True,\n",
    "#     metric_for_best_model=\"eval_macro_f1\",\n",
    "#     greater_is_better=True,\n",
    "#     warmup_steps=warmup_steps,  # –í–æ—Ä–º–∞–ø\n",
    "#     lr_scheduler_type=\"linear\",  # –®–µ–¥—É–ª–µ—Ä\n",
    "#     save_total_limit=2,\n",
    "# )\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=llm,\n",
    "    # args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=lambda p: {\n",
    "        \"macro_f1\": f1_score(p.label_ids, p.predictions > 0.5, average=\"macro\"),  # –ò–∑–º–µ–Ω–µ–Ω–æ\n",
    "        \"accuracy\": accuracy_score(p.label_ids, p.predictions > 0.5)\n",
    "    },\n",
    "    optimizers=(None, get_linear_schedule_with_warmup(\n",
    "        optimizer=torch.optim.AdamW(llm.parameters(), lr=3e-5),\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps\n",
    "    ))\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "best_model = AutoModelForCausalLM.from_pretrained(\n",
    "    os.path.join(training_args.output_dir, \"best_model\"),\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    load_in_4bit=True  # –ö–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2950f0cb-6b38-4a7d-b22c-14d889d8a1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad9ef4a-60b1-4b53-9280-77df87da5908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2453666-5681-41e3-a709-5854918a105f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "039767c2-4e2b-4972-9320-073ff17499b3",
   "metadata": {},
   "source": [
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –≤ submission —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π –ø–æ—Ä–æ–≥–∞ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "da186d57-c72d-4a30-9ded-6fe443a52d57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T20:38:04.147140Z",
     "iopub.status.busy": "2025-05-17T20:38:04.146276Z",
     "iopub.status.idle": "2025-05-17T20:38:09.406996Z",
     "shell.execute_reply": "2025-05-17T20:38:09.406232Z",
     "shell.execute_reply.started": "2025-05-17T20:38:04.147110Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 0s 1ms/step\n",
      "Best threshold: 0.30, F1-score: 0.8188\n",
      "231/231 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "val_probs = tfidf_nn.predict(\n",
    "    X_val_tfidf.toarray()\n",
    ")\n",
    "\n",
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for threshold in thresholds:\n",
    "    binary_preds = (val_probs > threshold).astype(int)\n",
    "    \n",
    "    current_f1 = f1_score(y_val, binary_preds, average='macro')\n",
    "    \n",
    "    if current_f1 > best_f1:\n",
    "        best_f1 = current_f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f'Best threshold: {best_threshold:.2f}, F1-score: {best_f1:.4f}')\n",
    "\n",
    "X_test_tfidf = tfidf.transform(test_df['text'].apply(tfidf_clean))\n",
    "\n",
    "test_probs = tfidf_nn.predict(X_test_tfidf.toarray())\n",
    "final_predictions = (test_probs > best_threshold).astype(int)\n",
    "\n",
    "test_df['labels'] = [' '.join(map(str, pred)) for pred in final_predictions]\n",
    "\n",
    "submission_df = test_df[['id', 'labels']]  \n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0b89f7-2a45-4254-bc63-9d9c225783d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_tfidf = tfidf.transform(test_df['text'].apply(tfidf_clean))\n",
    "\n",
    "# test_predictions = tfidf_nn.predict(X_test_tfidf.toarray())\n",
    "\n",
    "# binary_predictions = (test_predictions > 0.25).astype(int)\n",
    "\n",
    "# test_df['labels'] = [' '.join(map(str, pred)) for pred in binary_predictions]\n",
    "\n",
    "# submission_df = test_df[['id', 'labels']]  \n",
    "# submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
